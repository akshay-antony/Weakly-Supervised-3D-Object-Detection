{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/vlr/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from multiprocessing import reduction\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from WsdnnPIXOR import WSDDNPIXOR\n",
    "from dataset import KITTIBEV\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.ops import nms\n",
    "from post_processing import calculate_ap\n",
    "import wandb\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from visualize_dataset_new import plot_bev\n",
    "from loss import FocalLoss\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained(model, filename='40epoch'):\n",
    "    own_state = model.state_dict()\n",
    "    state_dict = torch.load(filename)\n",
    "    for name, param in state_dict.items():\n",
    "        if name not in own_state:\n",
    "                continue\n",
    "        if isinstance(param, nn.Parameter):\n",
    "            # backwards compatibility for serialized parameters\n",
    "            param = param.data\n",
    "        own_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, \n",
    "          model, \n",
    "          loss_fn,\n",
    "          optimizer, \n",
    "          test_loader,\n",
    "          num_classes=2):\n",
    "    loss_bce_total = 0.0\n",
    "    loss_total = 0.0\n",
    "    data_count = 0.0\n",
    "    total_target = torch.zeros((0, num_classes)).cuda()\n",
    "    total_preds = torch.zeros((0, num_classes)).cuda()\n",
    "    for iter, data in tqdm(enumerate(train_loader),\n",
    "                           total=len(train_loader),\n",
    "                           leave=False):\n",
    "        model = model.train()\n",
    "        bev = data['bev'].cuda()\n",
    "        labels = data['labels'].cuda()\n",
    "        #gt_boxes = data['gt_boxes'].cuda()\n",
    "        proposals = data['proposals'].squeeze().float().cuda()\n",
    "        proposals = torch.cuda.FloatTensor(proposals)\n",
    "        #gt_class_list = data['gt_class_list'].cuda()\n",
    "        #with torch.cuda.amp.autocast():\n",
    "        preds = model(bev, proposals)\n",
    "        preds_class = preds.sum(dim=0).reshape(1, -1)\n",
    "        preds_class_sigmoid = torch.sigmoid(preds_class)\n",
    "        total_preds = torch.cat([total_preds, preds_class_sigmoid], dim=0)\n",
    "        total_target = torch.cat([total_target, labels], dim=0)\n",
    "        preds_class = torch.clamp(preds_class, 0, 1)\n",
    "        loss = loss_fn(preds_class, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scaler.scale(loss).backward()\n",
    "        # scaler.step(optimizer)\n",
    "        # scaler.update()\n",
    "        loss_bce_total += F.binary_cross_entropy_with_logits(preds_class, labels, reduction='sum').item()\n",
    "        loss_total += loss.item() * bev.shape[0]\n",
    "        data_count += bev.shape[0]\n",
    "        if iter%500 == 0 and iter != 0:\n",
    "            map_class = map_classification(total_preds, total_target)\n",
    "            wandb.log({\"Loss\":loss_total / data_count})\n",
    "            print(\"Focal Loss: \", loss_total / data_count, \" BCE loss: \", loss_bce_total / data_count,  \" mAP: \", map_class)\n",
    "        # if iter%5000 == 0 and iter != 0:\n",
    "        #     model.eval()\n",
    "        #     validate(test_loader, model, loss_fn)\n",
    "    return loss_total / data_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(test_loader, \n",
    "             model, \n",
    "             loss_fn, \n",
    "             score_threshold=0.005,\n",
    "             nms_iou_threshold=0.5,\n",
    "             iou_list = [0.05, 0.1, 0.2, 0.3, 0.4],\n",
    "             inv_class=None,\n",
    "             direct_class=None):\n",
    "    np.random.seed(2)\n",
    "    num_classes = 2\n",
    "    loss_total = 0.0\n",
    "    data_count = 0.0\n",
    "    all_gt_boxes = torch.zeros((0, 6))\n",
    "    all_pred_boxes = torch.zeros((0, 7))\n",
    "    plotting_idxs = np.random.randint(0, 500, (50))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for iter, data in tqdm(enumerate(test_loader),\n",
    "                            total=len(test_loader),\n",
    "                            leave=False):\n",
    "            plotting_proposals = torch.zeros((0, 5))\n",
    "            plotting_gts = torch.zeros((0, 5))\n",
    "            bev = data['bev'].cuda()\n",
    "            labels = data['labels'].cuda()\n",
    "            gt_boxes = data['gt_boxes'].reshape(-1, 4) #.cuda()\n",
    "            proposals = data['proposals'].squeeze().float().cuda()\n",
    "            gt_class_list = data['gt_class_list'].reshape(-1) #.cuda()\n",
    "\n",
    "            cls_probs = model(bev, proposals)\n",
    "            preds_class = cls_probs.sum(dim=0).reshape(1, -1)\n",
    "            loss = loss_fn(preds_class, labels)\n",
    "            loss_total += loss.item()\n",
    "            data_count += bev.shape[0]\n",
    "\n",
    "            for i in range(gt_boxes.shape[0]):\n",
    "                modified_boxes = torch.cat([torch.tensor([iter, gt_class_list[i]]), gt_boxes[i]]).reshape(1, -1)\n",
    "                all_gt_boxes = torch.cat([all_gt_boxes, modified_boxes], dim=0)\n",
    "                plotting_gts = torch.cat([plotting_gts,\n",
    "                                          modified_boxes[0, 1:].reshape(1, -1)], dim=0)\n",
    "\n",
    "            for class_num in range(num_classes):\n",
    "                curr_class_scores = cls_probs[:, class_num]\n",
    "                valid_score_idx = torch.where(curr_class_scores >= score_threshold)\n",
    "                valid_scores = curr_class_scores[valid_score_idx]\n",
    "                valid_proposals = proposals[valid_score_idx]\n",
    "                retained_idx = nms(valid_proposals, valid_scores, nms_iou_threshold)\n",
    "                retained_scores = valid_scores[retained_idx]\n",
    "                retained_proposals = valid_proposals[retained_idx]\n",
    "\n",
    "                class_num_for_plotting = torch.ones((retained_proposals.shape[0], 1)) * class_num\n",
    "                plotting_proposals = torch.cat([plotting_proposals,\n",
    "                                                torch.cat([retained_proposals.detach().cpu(), \n",
    "                                                           class_num_for_plotting], dim=1)], dim=0)\n",
    "\n",
    "                for i in range(retained_proposals.shape[0]):\n",
    "                    modified_pred_boxes = torch.cat([torch.tensor([iter, class_num, retained_scores[i]]), \n",
    "                                                                retained_proposals[i].detach().cpu()]).reshape(1, -1)\n",
    "                    all_pred_boxes = torch.cat([all_pred_boxes, modified_pred_boxes], dim=0)\n",
    "\n",
    "            if iter in plotting_idxs:\n",
    "                all_boxes = []\n",
    "                all_gt_plotting_boxes = []\n",
    "                raw_image = plot_bev(bev[0].detach().cpu())\n",
    "\n",
    "                for idx in range(plotting_proposals.shape[0]):\n",
    "                    box_data = {\"position\": {\n",
    "                        \"minX\": plotting_proposals[idx, 1].item() / 350,\n",
    "                        \"minY\": plotting_proposals[idx, 0].item() / 400,\n",
    "                        \"maxX\": plotting_proposals[idx, 3].item() / 350,\n",
    "                        \"maxY\": plotting_proposals[idx, 2].item() / 400},\n",
    "                        \"class_id\": int(plotting_proposals[idx, 4].item()),\n",
    "                        \"box_caption\": inv_class[int(plotting_proposals[idx][4])],\n",
    "                        }\n",
    "                    all_boxes.append(box_data)\n",
    "                \n",
    "\n",
    "                for idx in range(plotting_gts.shape[0]):\n",
    "                    box_data_new = {\"position\": {\n",
    "                        \"minX\": plotting_gts[idx, 2].item() / 350,\n",
    "                        \"minY\": plotting_gts[idx, 1].item() / 400,\n",
    "                        \"maxX\": plotting_gts[idx, 4].item() / 350,\n",
    "                        \"maxY\": plotting_gts[idx, 3].item() / 400},\n",
    "                        \"class_id\": int(plotting_gts[idx, 0].item()),\n",
    "                        \"box_caption\": inv_class[int(plotting_gts[idx][0])],\n",
    "                        }\n",
    "                    all_gt_plotting_boxes.append(box_data_new)\n",
    "                    \n",
    "                box_image = wandb.Image(raw_image, \n",
    "                                        boxes={\"predictions\":\n",
    "                                        {\"box_data\": all_boxes,\n",
    "                                        \"class_labels\": inv_class},\n",
    "                                             \"ground_truth\":\n",
    "                                        {\"box_data\": all_gt_plotting_boxes,\n",
    "                                        \"class_labels\": inv_class}\n",
    "                                        })\n",
    "                wandb.log({\"Image proposals \" + str(iter): box_image})\n",
    "                box_image = wandb.Image(raw_image, \n",
    "                                        boxes= {\"predictions\":\n",
    "                                        {\"box_data\": all_gt_plotting_boxes,\n",
    "                                        \"class_labels\": inv_class}\n",
    "                                        })\n",
    "                wandb.log({\"Image gt \" + str(iter): box_image})\n",
    "                \n",
    "    for iou in iou_list:\n",
    "        #print(all_gt_boxes.shape, all_gt_boxes.shape)\n",
    "        AP = calculate_ap(all_pred_boxes, all_gt_boxes, iou, inv_class=inv_class, total_cls_num=num_classes)\n",
    "        mAP = 0 if len(AP) == 0 else sum(AP) / len(AP)\n",
    "        #return mAP.item(), AP\n",
    "        wandb.log({\"map@ \" + str(iou): mAP})\n",
    "        print(\"Iou \", iou, \" mAP \", mAP)\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_classification(output, target):\n",
    "    target = target.detach().cpu().numpy()\n",
    "    output = output.detach().cpu().numpy()\n",
    "    num_classes = target.shape[1]\n",
    "    ap = []\n",
    "    for class_id in range(num_classes):\n",
    "        output_req = output[:, class_id].astype('float32')\n",
    "        target_req = target[:, class_id].astype('float32')\n",
    "        output_req = output_req - 1e-5*target_req\n",
    "        if np.sum(target_req) == 0:\n",
    "            #ap.append(0)    \n",
    "            continue\n",
    "        curr_ap = sklearn.metrics.average_precision_score(target_req, output_req, average=None)\n",
    "        if not math.isnan(curr_ap):\n",
    "            ap.append(curr_ap)\n",
    "    return sum(ap) / (len(ap) if len(ap) > 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    }
   ],
   "source": [
    "valid_data_list_filename = \"./valid_data_list_after_threshold.txt\"\n",
    "lidar_folder_name = \"./data\"\n",
    "dataset = KITTIBEV(valid_data_list_filename=valid_data_list_filename, \n",
    "                        lidar_folder_name=lidar_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makshayantony12\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/vlr_project/wandb/run-20220426_095824-1cm197jb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/akshayantony12/vlr_project/runs/1cm197jb\" target=\"_blank\">worthy-meadow-72</a></strong> to <a href=\"https://wandb.ai/akshayantony12/vlr_project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    wandb.init(\"WSDNNPIXOR\")\n",
    "    epochs = 10\n",
    "    model = WSDDNPIXOR()\n",
    "    load_pretrained(model)\n",
    "\n",
    "    for params in model.backbone.parameters():\n",
    "        params.requires_grad = False\n",
    "\n",
    "    train_dataset_length = int(0.70 * len(dataset))\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_dataset_length,\n",
    "                                                        len(dataset) - train_dataset_length],\n",
    "                                                        generator=torch.Generator().manual_seed(10))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    print(len(train_dataset), len(test_dataset))\n",
    "\n",
    "    #scaler = torch.cuda.amp.GradScaler()\n",
    "    #loss_fn = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "    loss_fn = FocalLoss(alpha=0.25, gamma=2)\n",
    "    model = model.cuda()\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "    for i in range(epochs):\n",
    "        # if i%1 == 0:\n",
    "        #     model = model.eval()\n",
    "        #     mAP = validate(test_loader, \n",
    "        #                   model, \n",
    "        #                   loss_fn, \n",
    "        #                   inv_class=dataset.inv_class, \n",
    "        #                   direct_class=dataset.class_to_int)\n",
    "        model = model.train()\n",
    "        loss = train(train_loader, model, loss_fn, optimizer, test_loader)\n",
    "        print(\"Epoch average Loss: \", loss)\n",
    "        torch.save(model.state_dict(), \"model.pth\")\n",
    "        torch.save(optimizer.state_dict(), \"opt.pth\")\n",
    "        if i%1 == 0:\n",
    "            model = model.eval()\n",
    "            mAP = validate(test_loader, \n",
    "                          model, \n",
    "                          loss_fn, \n",
    "                          inv_class=dataset.inv_class, \n",
    "                          direct_class=dataset.class_to_int)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c3d0bf33d9b8f44ad31939f703eb731b3c8c625f2f2a5d3f62cdfd1d7b0393f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('vlr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
