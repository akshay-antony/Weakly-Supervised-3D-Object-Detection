{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from multiprocessing import reduction\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from WsdnnPIXOR import WSDDNPIXOR\n",
    "from dataset import KITTIBEV\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.ops import nms\n",
    "from post_processing import calculate_ap\n",
    "import wandb\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from visualize_dataset_new import plot_bev\n",
    "from loss import FocalLoss\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained(model, filename='40epoch'):\n",
    "    own_state = model.state_dict()\n",
    "    state_dict = torch.load(filename)\n",
    "    for name, param in state_dict.items():\n",
    "        if name not in own_state:\n",
    "                continue\n",
    "        if isinstance(param, nn.Parameter):\n",
    "            # backwards compatibility for serialized parameters\n",
    "            param = param.data\n",
    "        own_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, \n",
    "          model, \n",
    "          loss_fn,\n",
    "          optimizer, \n",
    "          test_loader,\n",
    "          num_classes=2):\n",
    "    loss_bce_total = 0.0\n",
    "    loss_total = 0.0\n",
    "    data_count = 0.0\n",
    "    total_target = torch.zeros((0, num_classes)).cuda()\n",
    "    total_preds = torch.zeros((0, num_classes)).cuda()\n",
    "    for iter, data in tqdm(enumerate(train_loader),\n",
    "                           total=len(train_loader),\n",
    "                           leave=False):\n",
    "        model = model.train()\n",
    "        bev = data['bev'].cuda()\n",
    "        labels = data['labels'].cuda()\n",
    "        #gt_boxes = data['gt_boxes'].cuda()\n",
    "        proposals = data['proposals'].squeeze().float().cuda()\n",
    "        proposals = torch.cuda.FloatTensor(proposals)\n",
    "        #gt_class_list = data['gt_class_list'].cuda()\n",
    "        #with torch.cuda.amp.autocast():\n",
    "        preds = model(bev, proposals)\n",
    "        preds_class = preds.sum(dim=0).reshape(1, -1)\n",
    "        preds_class_sigmoid = torch.sigmoid(preds_class)\n",
    "        total_preds = torch.cat([total_preds, preds_class_sigmoid], dim=0)\n",
    "        total_target = torch.cat([total_target, labels], dim=0)\n",
    "        preds_class = torch.clamp(preds_class, 0, 1)\n",
    "        loss = loss_fn(preds_class, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scaler.scale(loss).backward()\n",
    "        # scaler.step(optimizer)\n",
    "        # scaler.update()\n",
    "        loss_bce_total += F.binary_cross_entropy_with_logits(preds_class, labels, reduction='sum').item()\n",
    "        loss_total += loss.item() * bev.shape[0]\n",
    "        data_count += bev.shape[0]\n",
    "        if iter%500 == 0 and iter != 0:\n",
    "            map_class = map_classification(total_preds, total_target)\n",
    "            #wandb.log({\"Loss\":loss_total / data_count})\n",
    "            print(\"Focal Loss: \", loss_total / data_count, \" BCE loss: \", loss_bce_total / data_count,  \" mAP: \", map_class)\n",
    "        # if iter%5000 == 0 and iter != 0:\n",
    "        #     model.eval()\n",
    "        #     validate(test_loader, model, loss_fn)\n",
    "    return loss_total / data_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(test_loader, \n",
    "             model, \n",
    "             loss_fn, \n",
    "             score_threshold=0.005,\n",
    "             nms_iou_threshold=0.5,\n",
    "             iou_list = [0.05, 0.1, 0.2, 0.3, 0.4],\n",
    "             inv_class=None,\n",
    "             direct_class=None):\n",
    "    np.random.seed(2)\n",
    "    num_classes = 2\n",
    "    loss_total = 0.0\n",
    "    data_count = 0.0\n",
    "    all_gt_boxes = torch.zeros((0, 6))\n",
    "    all_pred_boxes = torch.zeros((0, 7))\n",
    "    plotting_idxs = np.random.randint(0, 500, (50))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for iter, data in tqdm(enumerate(test_loader),\n",
    "                            total=len(test_loader),\n",
    "                            leave=False):\n",
    "            plotting_proposals = torch.zeros((0, 5))\n",
    "            plotting_gts = torch.zeros((0, 5))\n",
    "            bev = data['bev'].cuda()\n",
    "            labels = data['labels'].cuda()\n",
    "            gt_boxes = data['gt_boxes'].reshape(-1, 4) #.cuda()\n",
    "            proposals = data['proposals'].squeeze().float().cuda()\n",
    "            gt_class_list = data['gt_class_list'].reshape(-1) #.cuda()\n",
    "\n",
    "            cls_probs = model(bev, proposals)\n",
    "            preds_class = cls_probs.sum(dim=0).reshape(1, -1)\n",
    "            loss = loss_fn(preds_class, labels)\n",
    "            loss_total += loss.item()\n",
    "            data_count += bev.shape[0]\n",
    "\n",
    "            for i in range(gt_boxes.shape[0]):\n",
    "                modified_boxes = torch.cat([torch.tensor([iter, gt_class_list[i]]), gt_boxes[i]]).reshape(1, -1)\n",
    "                all_gt_boxes = torch.cat([all_gt_boxes, modified_boxes], dim=0)\n",
    "                plotting_gts = torch.cat([plotting_gts,\n",
    "                                          modified_boxes[0, 1:].reshape(1, -1)], dim=0)\n",
    "\n",
    "            for class_num in range(num_classes):\n",
    "                curr_class_scores = cls_probs[:, class_num]\n",
    "                valid_score_idx = torch.where(curr_class_scores >= score_threshold)\n",
    "                valid_scores = curr_class_scores[valid_score_idx]\n",
    "                valid_proposals = proposals[valid_score_idx]\n",
    "                retained_idx = nms(valid_proposals, valid_scores, nms_iou_threshold)\n",
    "                retained_scores = valid_scores[retained_idx]\n",
    "                retained_proposals = valid_proposals[retained_idx]\n",
    "\n",
    "                class_num_for_plotting = torch.ones((retained_proposals.shape[0], 1)) * class_num\n",
    "                plotting_proposals = torch.cat([plotting_proposals,\n",
    "                                                torch.cat([retained_proposals.detach().cpu(), \n",
    "                                                           class_num_for_plotting], dim=1)], dim=0)\n",
    "\n",
    "                for i in range(retained_proposals.shape[0]):\n",
    "                    modified_pred_boxes = torch.cat([torch.tensor([iter, class_num, retained_scores[i]]), \n",
    "                                                                retained_proposals[i].detach().cpu()]).reshape(1, -1)\n",
    "                    all_pred_boxes = torch.cat([all_pred_boxes, modified_pred_boxes], dim=0)\n",
    "\n",
    "            if iter in plotting_idxs:\n",
    "                all_boxes = []\n",
    "                all_gt_plotting_boxes = []\n",
    "                raw_image = plot_bev(bev[0].detach().cpu())\n",
    "\n",
    "                for idx in range(plotting_proposals.shape[0]):\n",
    "                    box_data = {\"position\": {\n",
    "                        \"minX\": plotting_proposals[idx, 1].item() / 350,\n",
    "                        \"minY\": plotting_proposals[idx, 0].item() / 400,\n",
    "                        \"maxX\": plotting_proposals[idx, 3].item() / 350,\n",
    "                        \"maxY\": plotting_proposals[idx, 2].item() / 400},\n",
    "                        \"class_id\": int(plotting_proposals[idx, 4].item()),\n",
    "                        \"box_caption\": inv_class[int(plotting_proposals[idx][4])],\n",
    "                        }\n",
    "                    all_boxes.append(box_data)\n",
    "                \n",
    "\n",
    "                for idx in range(plotting_gts.shape[0]):\n",
    "                    box_data_new = {\"position\": {\n",
    "                        \"minX\": plotting_gts[idx, 2].item() / 350,\n",
    "                        \"minY\": plotting_gts[idx, 1].item() / 400,\n",
    "                        \"maxX\": plotting_gts[idx, 4].item() / 350,\n",
    "                        \"maxY\": plotting_gts[idx, 3].item() / 400},\n",
    "                        \"class_id\": int(plotting_gts[idx, 0].item()),\n",
    "                        \"box_caption\": inv_class[int(plotting_gts[idx][0])],\n",
    "                        }\n",
    "                    all_gt_plotting_boxes.append(box_data_new)\n",
    "                    \n",
    "                box_image = wandb.Image(raw_image, \n",
    "                                        boxes={\"predictions\":\n",
    "                                        {\"box_data\": all_boxes,\n",
    "                                        \"class_labels\": inv_class},\n",
    "                                             \"ground_truth\":\n",
    "                                        {\"box_data\": all_gt_plotting_boxes,\n",
    "                                        \"class_labels\": inv_class}\n",
    "                                        })\n",
    "                wandb.log({\"Image proposals \" + str(iter): box_image})\n",
    "                box_image = wandb.Image(raw_image, \n",
    "                                        boxes= {\"predictions\":\n",
    "                                        {\"box_data\": all_gt_plotting_boxes,\n",
    "                                        \"class_labels\": inv_class}\n",
    "                                        })\n",
    "                wandb.log({\"Image gt \" + str(iter): box_image})\n",
    "                \n",
    "    for iou in iou_list:\n",
    "        #print(all_gt_boxes.shape, all_gt_boxes.shape)\n",
    "        AP = calculate_ap(all_pred_boxes, all_gt_boxes, iou, inv_class=inv_class, total_cls_num=num_classes)\n",
    "        mAP = 0 if len(AP) == 0 else sum(AP) / len(AP)\n",
    "        #return mAP.item(), AP\n",
    "        wandb.log({\"map@ \" + str(iou): mAP})\n",
    "        print(\"Iou \", iou, \" mAP \", mAP)\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_classification(output, target):\n",
    "    target = target.detach().cpu().numpy()\n",
    "    output = output.detach().cpu().numpy()\n",
    "    num_classes = target.shape[1]\n",
    "    ap = []\n",
    "    for class_id in range(num_classes):\n",
    "        output_req = output[:, class_id].astype('float32')\n",
    "        target_req = target[:, class_id].astype('float32')\n",
    "        output_req = output_req - 1e-5*target_req\n",
    "        if np.sum(target_req) == 0:\n",
    "            #ap.append(0)    \n",
    "            continue\n",
    "        curr_ap = sklearn.metrics.average_precision_score(target_req, output_req, average=None)\n",
    "        if not math.isnan(curr_ap):\n",
    "            ap.append(curr_ap)\n",
    "    return sum(ap) / (len(ap) if len(ap) > 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "valid_data_list_filename = \"./valid_data_list_after_threshold.txt\"\n",
    "lidar_folder_name =  \"/media/akshay/Data/KITTI/\"\n",
    "dataset = KITTIBEV(valid_data_list_filename=valid_data_list_filename, \n",
    "                        lidar_folder_name=lidar_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4083 1751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4083 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003767 (3, 4) (3,) (186, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4083 [00:14<16:06:08, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004855 (4, 4) (4,) (270, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/4083 [00:14<6:54:39,  6.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "007131 (7, 4) (7,) (240, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/4083 [00:15<3:58:26,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000339 (10, 4) (10,) (244, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/4083 [00:15<2:35:09,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005226 (16, 4) (16,) (282, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/4083 [00:15<1:49:09,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003113 (12, 4) (12,) (236, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/4083 [00:16<1:21:32,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003802 (7, 4) (7,) (254, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/4083 [00:16<1:01:59,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004812 (3, 4) (3,) (252, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/4083 [00:16<49:58,  1.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005037 (4, 4) (4,) (248, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/4083 [00:17<40:58,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003716 (4, 4) (4,) (240, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/4083 [00:17<35:12,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006713 (2, 4) (2,) (150, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/4083 [00:18<27:28,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "007259 (5, 4) (5,) (232, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/4083 [00:18<24:06,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003270 (3, 4) (3,) (224, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/4083 [00:18<20:56,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "007260 (8, 4) (8,) (256, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/4083 [00:18<19:11,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006204 (2, 4) (2,) (198, 4)\n",
      "006333 (5, 4) (5,) (228, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/4083 [00:19<21:12,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002390 (1, 4) (1,) (190, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/4083 [00:19<28:03,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003380 (9, 4) (9,) (246, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/4083 [00:20<31:06,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "007145 (4, 4) (4,) (244, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/4083 [00:21<44:50,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006932 (14, 4) (14,) (272, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/4083 [00:22<58:40,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001029 (1, 4) (1,) (252, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/4083 [00:48<9:26:06,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004450 (4, 4) (4,) (216, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/4083 [01:23<18:14:36, 16.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006627 (7, 4) (7,) (224, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/4083 [01:33<11:21:02, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006356 (6, 4) (6,) (252, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 25/4083 [01:33<8:01:58,  7.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002647 (4, 4) (4,) (224, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 26/4083 [01:33<5:41:04,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005158 (1, 4) (1,) (184, 4)\n",
      "007176 (2, 4) (2,) (238, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 28/4083 [01:34<2:54:50,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000761 (4, 4) (4,) (220, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 29/4083 [01:34<2:06:41,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001500 (4, 4) (4,) (214, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 30/4083 [01:34<1:32:25,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "007283 (7, 4) (7,) (248, 4)\n",
      "002587 (1, 4) (1,) (184, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 32/4083 [01:34<52:20,  1.29it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000539 (1, 4) (1,) (194, 4)\n",
      "006781 (8, 4) (8,) (266, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 34/4083 [01:35<32:24,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005664 (5, 4) (5,) (236, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 35/4083 [01:35<27:07,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006258 (1, 4) (1,) (252, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 36/4083 [01:35<23:41,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004021 (1, 4) (1,) (252, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 37/4083 [01:36<20:42,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006360 (3, 4) (3,) (244, 4)\n",
      "001823 (2, 4) (2,) (228, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 38/4083 [01:36<28:58,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001966 (7, 4) (7,) (248, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 39/4083 [01:37<43:50,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001034 (3, 4) (3,) (202, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 40/4083 [01:38<42:44,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003584 (1, 4) (1,) (228, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 41/4083 [01:44<2:31:55,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006342 (10, 4) (10,) (248, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 42/4083 [01:49<3:17:46,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006597 (6, 4) (6,) (246, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 43/4083 [01:56<4:41:58,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000233 (1, 4) (1,) (232, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 44/4083 [02:04<6:03:07,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006835 (6, 4) (6,) (248, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 45/4083 [02:34<14:23:02, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003837 (2, 4) (2,) (232, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 46/4083 [02:35<10:15:37,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004154 (8, 4) (8,) (248, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 47/4083 [02:35<7:18:15,  6.52s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005591 (6, 4) (6,) (208, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 48/4083 [02:35<5:13:20,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004973 (1, 4) (1,) (236, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 49/4083 [02:36<3:48:22,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005764 (10, 4) (10,) (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 50/4083 [02:36<2:45:44,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002187 (10, 4) (10,) (234, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 51/4083 [02:36<2:02:54,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000262 (6, 4) (6,) (236, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 52/4083 [02:37<1:33:42,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001686 (2, 4) (2,) (186, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 53/4083 [02:37<1:12:53,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005775 (3, 4) (3,) (236, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 54/4083 [02:38<58:25,  1.15it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003848 (6, 4) (6,) (220, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 55/4083 [02:38<48:57,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000442 (7, 4) (7,) (228, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 56/4083 [02:38<41:33,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003315 (1, 4) (1,) (248, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 57/4083 [02:39<36:20,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005345 (5, 4) (5,) (240, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 58/4083 [02:39<33:01,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "007378 (3, 4) (3,) (220, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 59/4083 [02:40<33:24,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006926 (14, 4) (14,) (248, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 60/4083 [02:40<39:16,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002332 (7, 4) (7,) (176, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 61/4083 [02:45<2:05:47,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004716 (6, 4) (6,) (244, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 62/4083 [02:47<2:12:01,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004031 (7, 4) (7,) (228, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 63/4083 [02:55<4:15:00,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000435 (5, 4) (5,) (268, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 64/4083 [03:07<6:45:25,  6.05s/it]"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (/home/akshay/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1204175)",
      "at /home/akshay/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (/home/akshay/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223212)",
      "at v.dispose (/home/akshay/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1216694)",
      "at /home/akshay/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533674",
      "at t.swallowExceptions (/home/akshay/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:913059)",
      "at dispose (/home/akshay/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533652)",
      "at t.RawSession.dispose (/home/akshay/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #wandb.init(project=\"WSDNNPIXOR\")\n",
    "    epochs = 10\n",
    "    model = WSDDNPIXOR()\n",
    "    load_pretrained(model)\n",
    "\n",
    "    for params in model.backbone.parameters():\n",
    "        params.requires_grad = False\n",
    "\n",
    "    train_dataset_length = int(0.70 * len(dataset))\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_dataset_length,\n",
    "                                                        len(dataset) - train_dataset_length],\n",
    "                                                        generator=torch.Generator().manual_seed(10))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    print(len(train_dataset), len(test_dataset))\n",
    "\n",
    "    #scaler = torch.cuda.amp.GradScaler()\n",
    "    #loss_fn = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "    loss_fn = FocalLoss(alpha=0.25, gamma=2)\n",
    "    model = model.cuda()\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "    for i in range(epochs):\n",
    "        # if i%1 == 0:\n",
    "        #     model = model.eval()\n",
    "        #     mAP = validate(test_loader, \n",
    "        #                   model, \n",
    "        #                   loss_fn, \n",
    "        #                   inv_class=dataset.inv_class, \n",
    "        #                   direct_class=dataset.class_to_int)\n",
    "        model = model.train()\n",
    "        loss = train(train_loader, model, loss_fn, optimizer, test_loader)\n",
    "        print(\"Epoch average Loss: \", loss)\n",
    "        torch.save(model.state_dict(), \"model.pth\")\n",
    "        torch.save(optimizer.state_dict(), \"opt.pth\")\n",
    "        if i%1 == 0:\n",
    "            model = model.eval()\n",
    "            mAP = validate(test_loader, \n",
    "                          model, \n",
    "                          loss_fn, \n",
    "                          inv_class=dataset.inv_class, \n",
    "                          direct_class=dataset.class_to_int)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c3d0bf33d9b8f44ad31939f703eb731b3c8c625f2f2a5d3f62cdfd1d7b0393f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('vlr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
