{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from multiprocessing import reduction\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from WsdnnPIXOR import WSDDNPIXOR\n",
    "from dataset import KITTIBEV\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.ops import nms\n",
    "from post_processing import calculate_ap\n",
    "import wandb\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from visualize_dataset_new import plot_bev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained(model, filename='40epoch'):\n",
    "    own_state = model.state_dict()\n",
    "    state_dict = torch.load(filename)\n",
    "    for name, param in state_dict.items():\n",
    "        if name not in own_state:\n",
    "                continue\n",
    "        if isinstance(param, nn.Parameter):\n",
    "            # backwards compatibility for serialized parameters\n",
    "            param = param.data\n",
    "        own_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, \n",
    "          model, \n",
    "          loss_fn,\n",
    "          optimizer, \n",
    "          test_loader):\n",
    "    loss_total = 0.0\n",
    "    data_count = 0.0\n",
    "    total_target = torch.zeros((0, 8)).cuda()\n",
    "    total_preds = torch.zeros((0, 8)).cuda()\n",
    "    for iter, data in tqdm(enumerate(train_loader),\n",
    "                           total=len(train_loader),\n",
    "                           leave=False):\n",
    "        model = model.train()\n",
    "        bev = data['bev'].cuda()\n",
    "        labels = data['labels'].cuda()\n",
    "        #gt_boxes = data['gt_boxes'].cuda()\n",
    "        proposals = data['proposals'].squeeze().float().cuda()\n",
    "        proposals = torch.cuda.FloatTensor(proposals)\n",
    "        #gt_class_list = data['gt_class_list'].cuda()\n",
    "        #with torch.cuda.amp.autocast():\n",
    "        preds = model(bev, proposals)\n",
    "        preds_class = preds.sum(dim=0).reshape(1, -1)\n",
    "        preds_class_sigmoid = torch.sigmoid(preds_class)\n",
    "        total_preds = torch.cat([total_preds, preds_class_sigmoid], dim=0)\n",
    "        total_target = torch.cat([total_target, labels], dim=0)\n",
    "        preds_class = torch.clamp(preds_class, 0, 1)\n",
    "        loss = loss_fn(preds_class, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scaler.scale(loss).backward()\n",
    "        # scaler.step(optimizer)\n",
    "        # scaler.update()\n",
    "\n",
    "        loss_total += loss.item() * bev.shape[0]\n",
    "        data_count += bev.shape[0]\n",
    "        if iter%500 == 0 and iter != 0:\n",
    "            map_class = map_classification(total_preds, total_target)\n",
    "            wandb.log({\"Loss\":loss_total / data_count})\n",
    "            print(\"Loss: \", loss_total / data_count, \" mAP: \", map_class)\n",
    "        # if iter%5000 == 0 and iter != 0:\n",
    "        #     model.eval()\n",
    "        #     validate(test_loader, model, loss_fn)\n",
    "    return loss_total / data_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(test_loader, \n",
    "             model, \n",
    "             loss_fn, \n",
    "             score_threshold=0.005,\n",
    "             nms_iou_threshold=0.5,\n",
    "             iou_list = [0.05, 0.1, 0.2, 0.3, 0.4],\n",
    "             inv_class=None,\n",
    "             direct_class=None):\n",
    "    np.random.seed(2)\n",
    "    num_classes = 8\n",
    "    loss_total = 0.0\n",
    "    data_count = 0.0\n",
    "    all_gt_boxes = torch.zeros((0, 6))\n",
    "    all_pred_boxes = torch.zeros((0, 7))\n",
    "    plotting_idxs = np.random.randint(0, 500, (50))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for iter, data in tqdm(enumerate(test_loader),\n",
    "                            total=len(test_loader),\n",
    "                            leave=False):\n",
    "            plotting_proposals = torch.zeros((0, 5))\n",
    "            plotting_gts = torch.zeros((0, 5))\n",
    "            bev = data['bev'].cuda()\n",
    "            labels = data['labels'].cuda()\n",
    "            gt_boxes = data['gt_boxes'].reshape(-1, 4) #.cuda()\n",
    "            proposals = data['proposals'].squeeze().float().cuda()\n",
    "            gt_class_list = data['gt_class_list'].reshape(-1) #.cuda()\n",
    "\n",
    "            cls_probs = model(bev, proposals)\n",
    "            preds_class = cls_probs.sum(dim=0).reshape(1, -1)\n",
    "            loss = loss_fn(preds_class, labels)\n",
    "            loss_total += loss.item()\n",
    "            data_count += bev.shape[0]\n",
    "\n",
    "            for i in range(gt_boxes.shape[0]):\n",
    "                modified_boxes = torch.cat([torch.tensor([iter, gt_class_list[i]]), gt_boxes[i]]).reshape(1, -1)\n",
    "                all_gt_boxes = torch.cat([all_gt_boxes, modified_boxes], dim=0)\n",
    "                plotting_gts = torch.cat([plotting_gts,\n",
    "                                          modified_boxes[0, 1:].reshape(1, -1)], dim=0)\n",
    "\n",
    "            for class_num in range(num_classes):\n",
    "                curr_class_scores = cls_probs[:, class_num]\n",
    "                valid_score_idx = torch.where(curr_class_scores >= score_threshold)\n",
    "                valid_scores = curr_class_scores[valid_score_idx]\n",
    "                valid_proposals = proposals[valid_score_idx]\n",
    "                retained_idx = nms(valid_proposals, valid_scores, nms_iou_threshold)\n",
    "                retained_scores = valid_scores[retained_idx]\n",
    "                retained_proposals = valid_proposals[retained_idx]\n",
    "\n",
    "                class_num_for_plotting = torch.ones((retained_proposals.shape[0], 1)) * class_num\n",
    "                plotting_proposals = torch.cat([plotting_proposals,\n",
    "                                                torch.cat([retained_proposals.detach().cpu(), \n",
    "                                                           class_num_for_plotting], dim=1)], dim=0)\n",
    "\n",
    "                for i in range(retained_proposals.shape[0]):\n",
    "                    modified_pred_boxes = torch.cat([torch.tensor([iter, class_num, retained_scores[i]]), \n",
    "                                                                retained_proposals[i].detach().cpu()]).reshape(1, -1)\n",
    "                    all_pred_boxes = torch.cat([all_pred_boxes, modified_pred_boxes], dim=0)\n",
    "\n",
    "            if iter in plotting_idxs:\n",
    "                all_boxes = []\n",
    "                all_gt_plotting_boxes = []\n",
    "                raw_image = plot_bev(bev[0].detach().cpu())\n",
    "\n",
    "                for idx in range(plotting_proposals.shape[0]):\n",
    "                    box_data = {\"position\": {\n",
    "                        \"minX\": plotting_proposals[idx, 1].item() / 700,\n",
    "                        \"minY\": plotting_proposals[idx, 0].item() / 800,\n",
    "                        \"maxX\": plotting_proposals[idx, 3].item() / 700,\n",
    "                        \"maxY\": plotting_proposals[idx, 2].item() / 800},\n",
    "                        \"class_id\": int(plotting_proposals[idx, 4].item()),\n",
    "                        \"box_caption\": inv_class[int(plotting_proposals[idx][4])],\n",
    "                        }\n",
    "                    all_boxes.append(box_data)\n",
    "                \n",
    "\n",
    "                for idx in range(plotting_gts.shape[0]):\n",
    "                    box_data_new = {\"position\": {\n",
    "                        \"minX\": plotting_gts[idx, 2].item() / 700,\n",
    "                        \"minY\": plotting_gts[idx, 1].item() / 800,\n",
    "                        \"maxX\": plotting_gts[idx, 4].item() / 700,\n",
    "                        \"maxY\": plotting_gts[idx, 3].item() / 800},\n",
    "                        \"class_id\": int(plotting_gts[idx, 0].item()),\n",
    "                        \"box_caption\": inv_class[int(plotting_gts[idx][0])],\n",
    "                        }\n",
    "                    all_gt_plotting_boxes.append(box_data_new)\n",
    "                    \n",
    "                box_image = wandb.Image(raw_image, \n",
    "                                        boxes={\"predictions\":\n",
    "                                        {\"box_data\": all_boxes,\n",
    "                                        \"class_labels\": inv_class},\n",
    "                                             \"ground_truth\":\n",
    "                                        {\"box_data\": all_gt_plotting_boxes,\n",
    "                                        \"class_labels\": inv_class}\n",
    "                                        })\n",
    "                wandb.log({\"Image proposals \" + str(iter): box_image})\n",
    "                box_image = wandb.Image(raw_image, \n",
    "                                        boxes= {\"predictions\":\n",
    "                                        {\"box_data\": all_gt_plotting_boxes,\n",
    "                                        \"class_labels\": inv_class}\n",
    "                                        })\n",
    "                wandb.log({\"Image gt \" + str(iter): box_image})\n",
    "                \n",
    "    for iou in iou_list:\n",
    "        #print(all_gt_boxes.shape, all_gt_boxes.shape)\n",
    "        AP = calculate_ap(all_pred_boxes, all_gt_boxes, iou, inv_class=inv_class)\n",
    "        mAP = 0 if len(AP) == 0 else sum(AP) / len(AP)\n",
    "        #return mAP.item(), AP\n",
    "        wandb.log({\"map@ \" + str(iou): mAP})\n",
    "        print(\"Iou \", iou, \" mAP \", mAP)\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_classification(output, target):\n",
    "    target = target.detach().cpu().numpy()\n",
    "    output = output.detach().cpu().numpy()\n",
    "    num_classes = target.shape[1]\n",
    "    ap = []\n",
    "    for class_id in range(num_classes):\n",
    "        output_req = output[:, class_id].astype('float32')\n",
    "        target_req = target[:, class_id].astype('float32')\n",
    "        output_req = output_req - 1e-5*target_req\n",
    "        if np.sum(target_req) == 0:\n",
    "            #ap.append(0)    \n",
    "            continue\n",
    "        curr_ap = sklearn.metrics.average_precision_score(target_req, output_req, average=None)\n",
    "        if not math.isnan(curr_ap):\n",
    "            ap.append(curr_ap)\n",
    "    return sum(ap) / (len(ap) if len(ap) > 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5840 0 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "valid_data_list_filename = \"./valid_data_list_after_threshold.txt\"\n",
    "lidar_folder_name = \"./data\"\n",
    "dataset = KITTIBEV(valid_data_list_filename=valid_data_list_filename, \n",
    "                        lidar_folder_name=lidar_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3p4njxbd) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">proud-surf-60</strong>: <a href=\"https://wandb.ai/akshayantony12/vlr_project/runs/3p4njxbd\" target=\"_blank\">https://wandb.ai/akshayantony12/vlr_project/runs/3p4njxbd</a><br/>Synced 6 W&B file(s), 70 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220425_174835-3p4njxbd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3p4njxbd). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/vlr_project/wandb/run-20220425_174908-24j1toht</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/akshayantony12/vlr_project/runs/24j1toht\" target=\"_blank\">cool-hill-61</a></strong> to <a href=\"https://wandb.ai/akshayantony12/vlr_project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4087 1753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 501/4087 [02:54<20:59,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.3026042333451375  mAP:  0.24038426394615905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1001/4087 [05:49<18:03,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.307942754307603  mAP:  0.23625009255965623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1501/4087 [08:45<15:18,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.301063739989704  mAP:  0.2369255293251407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 2001/4087 [11:41<11:58,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.310116266568569  mAP:  0.23712463053920943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 2501/4087 [14:33<09:08,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.310751150038047  mAP:  0.23745280730935597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3001/4087 [17:27<06:23,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.3088419203589465  mAP:  0.23784306632583088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 3501/4087 [20:24<03:29,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.3051929676348575  mAP:  0.2371847188408679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 4001/4087 [23:16<00:30,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.3032058375094815  mAP:  0.23626618702443386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch average Loss:  5.302261234026277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iou  0.05  mAP  tensor(7.6268e-05)\n",
      "Iou  0.1  mAP  tensor(6.2490e-05)\n",
      "Iou  0.2  mAP  tensor(3.9454e-05)\n",
      "Iou  0.3  mAP  tensor(3.3069e-05)\n",
      "Iou  0.4  mAP  tensor(2.4682e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 501/4087 [03:09<22:54,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.29702847833167  mAP:  0.23076455784084005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1001/4087 [06:18<19:35,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.298159085042946  mAP:  0.2292106394571593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1501/4087 [09:29<17:07,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.306531126005979  mAP:  0.22909571293700395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 2001/4087 [12:45<13:38,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.305221987643401  mAP:  0.22946269456788163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/vlr_project/main.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000006vscode-remote?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000006vscode-remote?line=23'>24</a>\u001b[0m     \u001b[39m# if i%1 == 0:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000006vscode-remote?line=24'>25</a>\u001b[0m     \u001b[39m#     model = model.eval()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000006vscode-remote?line=28'>29</a>\u001b[0m     \u001b[39m#                   inv_class=dataset.inv_class, \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000006vscode-remote?line=29'>30</a>\u001b[0m     \u001b[39m#                   direct_class=dataset.class_to_int)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000006vscode-remote?line=30'>31</a>\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000006vscode-remote?line=31'>32</a>\u001b[0m     loss \u001b[39m=\u001b[39m train(train_loader, model, loss_fn, optimizer, test_loader)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000006vscode-remote?line=32'>33</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEpoch average Loss: \u001b[39m\u001b[39m\"\u001b[39m, loss)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000006vscode-remote?line=33'>34</a>\u001b[0m     torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), \u001b[39m\"\u001b[39m\u001b[39mmodel.pth\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/ubuntu/vlr_project/main.ipynb Cell 3'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, loss_fn, optimizer, test_loader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000002vscode-remote?line=30'>31</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000002vscode-remote?line=31'>32</a>\u001b[0m \u001b[39m# scaler.scale(loss).backward()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000002vscode-remote?line=32'>33</a>\u001b[0m \u001b[39m# scaler.step(optimizer)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000002vscode-remote?line=33'>34</a>\u001b[0m \u001b[39m# scaler.update()\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000002vscode-remote?line=35'>36</a>\u001b[0m loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem() \u001b[39m*\u001b[39m bev\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000002vscode-remote?line=36'>37</a>\u001b[0m data_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m bev\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2_andrew/home/ubuntu/vlr_project/main.ipynb#ch0000002vscode-remote?line=37'>38</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39miter\u001b[39m\u001b[39m%\u001b[39m\u001b[39m500\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    wandb.init(\"WSDNNPIXOR\")\n",
    "    epochs = 10\n",
    "    model = WSDDNPIXOR()\n",
    "    #load_pretrained(model)\n",
    "\n",
    "    # for params in model.backbone.parameters():\n",
    "    #     params.requires_grad = False\n",
    "\n",
    "    train_dataset_length = int(0.70 * len(dataset))\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_dataset_length,\n",
    "                                                        len(dataset) - train_dataset_length],\n",
    "                                                        generator=torch.Generator().manual_seed(10))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    print(len(train_dataset), len(test_dataset))\n",
    "\n",
    "    #scaler = torch.cuda.amp.GradScaler()\n",
    "    loss_fn = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "    model = model.cuda()\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    for i in range(epochs):\n",
    "        # if i%1 == 0:\n",
    "        #     model = model.eval()\n",
    "        #     mAP = validate(test_loader, \n",
    "        #                   model, \n",
    "        #                   loss_fn, \n",
    "        #                   inv_class=dataset.inv_class, \n",
    "        #                   direct_class=dataset.class_to_int)\n",
    "        model = model.train()\n",
    "        loss = train(train_loader, model, loss_fn, optimizer, test_loader)\n",
    "        print(\"Epoch average Loss: \", loss)\n",
    "        torch.save(model.state_dict(), \"model.pth\")\n",
    "        torch.save(optimizer.state_dict(), \"opt.pth\")\n",
    "        if i%1 == 0:\n",
    "            model = model.eval()\n",
    "            mAP = validate(test_loader, \n",
    "                          model, \n",
    "                          loss_fn, \n",
    "                          inv_class=dataset.inv_class, \n",
    "                          direct_class=dataset.class_to_int)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c3d0bf33d9b8f44ad31939f703eb731b3c8c625f2f2a5d3f62cdfd1d7b0393f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('vlr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
